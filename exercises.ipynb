{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Our jupyter/datascience-notebook Docker container comes with \n",
    "# BeautifulSoup4 and requests, both popular libraries!\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "START_URL = 'https://brickset.com/sets/year-2016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise #1: Get the titles for each \"brickset\" on the first page\n",
    "\n",
    "def get_soup(url):\n",
    "    contents = requests.get(url).content\n",
    "    return BeautifulSoup(contents, 'html.parser')\n",
    "\n",
    "def get_titles(soup):    \n",
    "    \"\"\" Returns a list of titles on the page \"\"\"\n",
    "    # the \"soup\" parameter is of the type that is\n",
    "    # returned by Beautiful Soup when it parses HTML.\n",
    "    # The function should then use the object to\n",
    "    # extract a list of titles (of the lego sets)\n",
    "    #\n",
    "    # Lookup the documentation for Beautiful Soup\n",
    "    # Figure out how to select the text of the title\n",
    "    # of each legoset. A title should look like: \n",
    "    # \"10252: Volkswagen Beetle\"\n",
    "    tags = soup.select('h1 a')\n",
    "    titles = [h1.get_text() for h1 in tags]\n",
    "    return titles\n",
    "\n",
    "\n",
    "def parse_bricks(url):\n",
    "    \"\"\" Fetches Lego Bricks page and extracts titles \"\"\"\n",
    "    # Lookup the documentation to the \"requests\" library\n",
    "    #\n",
    "    # Use requests to make a get request to the\n",
    "    # url given in the argument \"url\" (which is a string)\n",
    "    # and get the raw HTML body of the response\n",
    "    #\n",
    "    # Use \"BeautifulSoup\" to parse this HTML. \n",
    "    #\n",
    "    # Use the \"get_titles\" function to extract the\n",
    "    # titles from the BeautifulSoup object.\n",
    "    #\n",
    "    # Return the titles\n",
    "    soup = get_soup(START_URL)\n",
    "    return get_titles(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10251:  Brick Bank',\n",
       " '10252:  Volkswagen Beetle',\n",
       " '10253:  Big Ben',\n",
       " '10254:  Winter Holiday Train',\n",
       " '10654:  XL Creative Brick Box',\n",
       " '10702:  Creative Building Set',\n",
       " '10705:  Creative Building Basket',\n",
       " '10720:  Police Helicopter Chase',\n",
       " '10721:  Iron Man vs. Loki',\n",
       " '10722:  Snake Showdown',\n",
       " \"10723:  Ariel's Dolphin Carriage\",\n",
       " '10724:  Batman & Superman vs. Lex Luthor',\n",
       " '10725:  Lost Temple',\n",
       " \"10726:  Stephanie's Horse Carriage\",\n",
       " \"10727:  Emma's Ice Cream Truck\",\n",
       " \"10728:  Mia's Vet Clinic\",\n",
       " \"10729:  Cinderella's Carriage\",\n",
       " '10801:  Baby Animals',\n",
       " '10802:  Savanna',\n",
       " '10803:  Arctic',\n",
       " '10804:  Jungle',\n",
       " '10805:  Around the World',\n",
       " '10806:  Horses',\n",
       " '10807:  Horse Trailer',\n",
       " '10808:  Little Plane']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bricks = parse_bricks(START_URL)\n",
    "bricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Exercise #2\n",
    "\n",
    "# Now write code that gets you all the links from ALL the pages.\n",
    "\n",
    "# HINT: you will probably want to extract the URL in the \"next\" button on \n",
    "# the bottom of the search pagination, which looks like \">\".\n",
    "\n",
    "# HINT HINT: Think of the previous exercise on API's and internet data.\n",
    "# The Pokemon API returned JSON, that we converted to a dictionary, that\n",
    "# had a nice structure. In particular, there were two top-level keys of interest, \n",
    "# one had the \"results\" in a list, the other was the \"next\" url to call to get\n",
    "# more items. If you can replicate this return structure, you will be able to \n",
    "# almost reuse the while loop you had there!\n",
    "\n",
    "# HINT HINT HINT: There's no reason you shouldn't be able to reuse the previous \n",
    "# functions (get_titles and parse_bricks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://brickset.com/sets/year-2016\n",
      "https://brickset.com/sets/year-2016/page-2\n",
      "https://brickset.com/sets/year-2016/page-3\n",
      "https://brickset.com/sets/year-2016/page-4\n",
      "https://brickset.com/sets/year-2016/page-5\n",
      "https://brickset.com/sets/year-2016/page-6\n",
      "https://brickset.com/sets/year-2016/page-7\n",
      "https://brickset.com/sets/year-2016/page-8\n",
      "https://brickset.com/sets/year-2016/page-9\n",
      "https://brickset.com/sets/year-2016/page-10\n",
      "https://brickset.com/sets/year-2016/page-11\n",
      "https://brickset.com/sets/year-2016/page-12\n",
      "https://brickset.com/sets/year-2016/page-13\n",
      "https://brickset.com/sets/year-2016/page-14\n",
      "https://brickset.com/sets/year-2016/page-15\n",
      "https://brickset.com/sets/year-2016/page-16\n",
      "https://brickset.com/sets/year-2016/page-17\n",
      "https://brickset.com/sets/year-2016/page-18\n",
      "https://brickset.com/sets/year-2016/page-19\n",
      "https://brickset.com/sets/year-2016/page-20\n",
      "https://brickset.com/sets/year-2016/page-21\n",
      "https://brickset.com/sets/year-2016/page-22\n",
      "https://brickset.com/sets/year-2016/page-23\n",
      "https://brickset.com/sets/year-2016/page-24\n",
      "https://brickset.com/sets/year-2016/page-25\n",
      "https://brickset.com/sets/year-2016/page-26\n",
      "https://brickset.com/sets/year-2016/page-27\n",
      "https://brickset.com/sets/year-2016/page-28\n",
      "https://brickset.com/sets/year-2016/page-29\n",
      "https://brickset.com/sets/year-2016/page-30\n",
      "https://brickset.com/sets/year-2016/page-31\n",
      "https://brickset.com/sets/year-2016/page-32\n",
      "https://brickset.com/sets/year-2016/page-33\n",
      "https://brickset.com/sets/year-2016/page-34\n"
     ]
    }
   ],
   "source": [
    "# note: reusing the previous functions isn't ideal because parse_bricks loads the page but discards the loaded page\n",
    "# so we'll just reuse get_titles and not parse_bricks\n",
    "\n",
    "def get_next(soup):\n",
    "    list_item = soup.find('li', ['next'])\n",
    "    if list_item: \n",
    "        anchor = list_item.find('a')\n",
    "        if anchor:\n",
    "            return anchor['href']\n",
    "    return None\n",
    "\n",
    "def get_all_titles(start_url):\n",
    "    next_url = start_url\n",
    "    titles = []\n",
    "    while next_url:\n",
    "        print(next_url)\n",
    "        soup = get_soup(next_url)\n",
    "        titles += get_titles(soup)\n",
    "        next_url = get_next(soup)\n",
    "    return titles\n",
    "    \n",
    "titles = get_all_titles(START_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "name": "exercises.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
